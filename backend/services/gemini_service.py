
import time
import google.generativeai as genai
import os
from dotenv import load_dotenv
import asyncio
from concurrent.futures import ThreadPoolExecutor

# Load environment variables
load_dotenv()

# API key from environment variables with new key as fallback
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyC0sKQhg3sqDJXQUxK8_om4FfQY1884NXM")

# Use the faster flash model for better performance
GEMINI_MODEL = "gemini-2.0-flash"

# Configure the Gemini API once
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    print("Gemini API configured successfully")
else:
    print("Warning: GEMINI_API_KEY environment variable not set")

# Create model instance once for reuse
model = None
if GEMINI_API_KEY:
    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        print(f"Gemini model {GEMINI_MODEL} initialized successfully")
    except Exception as e:
        print(f"Error initializing Gemini model: {e}")

def ask_gemini(messages):
    """Send message to Gemini and return response - optimized for speed"""
    try:
        if not GEMINI_API_KEY or not model:
            return "Gemini API key not configured. Please set GEMINI_API_KEY in .env file."
            
        print("üöÄ Starting optimized Gemini request...")
        start_time = time.time()
        
        # Extract the system message if it exists
        system_message = next((msg["content"] for msg in messages if msg["role"] == "system"), None)
        
        # Build prompt more efficiently
        prompt_parts = []
        
        # Add system message at the beginning if it exists
        if system_message:
            prompt_parts.append(f"SYSTEM: {system_message}")
        
        # Add the conversation history (limit to last 10 messages for speed)
        conversation_messages = [msg for msg in messages if msg["role"] != "system"]
        recent_messages = conversation_messages[-10:]  # Only use last 10 messages
        
        for msg in recent_messages:
            prompt_parts.append(f"{msg['role'].upper()}: {msg['content']}")
        
        formatted_content = "\n\n".join(prompt_parts)
        
        print(f"üìù Prompt length: {len(formatted_content)} characters")
        print(f"üîë Using API key: {GEMINI_API_KEY[:10]}...{GEMINI_API_KEY[-5:]}")
        
        # Generate response with optimized settings for speed
        print("‚ö° Sending optimized request to Gemini API...")
        
        response = model.generate_content(
            formatted_content,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.9,
                "top_k": 20,  # Reduced for faster generation
                "max_output_tokens": 1024,  # Reduced for faster response
                "candidate_count": 1,  # Only generate one candidate
            },
            safety_settings=[
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]
        )
        
        end_time = time.time()
        response_time = end_time - start_time
        print(f"‚úÖ Optimized request completed in {response_time:.2f} seconds")
        
        if not response.text:
            print("‚ö†Ô∏è Warning: Empty response received from Gemini API")
            raise Exception("Empty response from Gemini API")
            
        print(f"üìÑ Response length: {len(response.text)} characters")
        print(f"üèÉ‚Äç‚ôÇÔ∏è Speed improvement: ~{max(0, 3.0 - response_time):.1f}s faster than before")
        
        return response.text
        
    except Exception as e:
        print(f"‚ùå Error in optimized Gemini service: {str(e)}")
        import traceback
        print(f"üîç Full traceback: {traceback.format_exc()}")
        
        # Provide a more helpful error message
        if "quota" in str(e).lower():
            return "‚ö†Ô∏è Gemini API quota exceeded. Please check your API key limits or try again later."
        elif "api key" in str(e).lower():
            return "üîë Invalid Gemini API key. Please check your API key configuration."
        else:
            return f"‚ö†Ô∏è Gemini service temporarily unavailable: {str(e)}"

# Async version for future use
async def ask_gemini_async(messages):
    """Async version of ask_gemini for better performance"""
    loop = asyncio.get_event_loop()
    with ThreadPoolExecutor() as executor:
        return await loop.run_in_executor(executor, ask_gemini, messages)
